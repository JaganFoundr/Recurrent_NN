{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy dataset: sequence of numbers and their labels (sum of the sequence)\n",
    "sequences = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "]\n",
    "labels = [6, 15, 24, 33]  # The sum of each sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        # output_size should be 1 since we're predicting the sum (a scalar)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        out, _ = self.rnn(x)  # output: (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        # We only need the output from the last time step\n",
    "        last_hidden = out[:, -1, :]  # shape: (batch_size, hidden_size)\n",
    "        \n",
    "        # Predict a scalar value, so output size is 1 (scalar)\n",
    "        output = self.linear(last_hidden)  # shape: (batch_size, 1)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(1, 10, batch_first=True)\n",
      "  (linear): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model, loss_fn, optimizer\n",
    "input_size=1\n",
    "hidden_size=10\n",
    "output_size=1\n",
    "\n",
    "model=RNN(input_size, hidden_size, output_size)\n",
    "\n",
    "loss_fn=nn.MSELoss()\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1100], Loss: 13.835240051703295\n",
      "Epoch [2/1100], Loss: 13.805712706393251\n",
      "Epoch [3/1100], Loss: 13.776243614164741\n",
      "Epoch [4/1100], Loss: 13.746839841893461\n",
      "Epoch [5/1100], Loss: 13.717473663194141\n",
      "Epoch [6/1100], Loss: 13.688132504009502\n",
      "Epoch [7/1100], Loss: 13.658801983926423\n",
      "Epoch [8/1100], Loss: 13.629464874000405\n",
      "Epoch [9/1100], Loss: 13.600103348632047\n",
      "Epoch [10/1100], Loss: 13.570671352798854\n",
      "Epoch [11/1100], Loss: 13.541149641148479\n",
      "Epoch [12/1100], Loss: 13.5114938525831\n",
      "Epoch [13/1100], Loss: 13.481656614616952\n",
      "Epoch [14/1100], Loss: 13.451589006157121\n",
      "Epoch [15/1100], Loss: 13.421227305438379\n",
      "Epoch [16/1100], Loss: 13.390488041854269\n",
      "Epoch [17/1100], Loss: 13.35926101818427\n",
      "Epoch [18/1100], Loss: 13.327433693493788\n",
      "Epoch [19/1100], Loss: 13.294843814044725\n",
      "Epoch [20/1100], Loss: 13.26131225420977\n",
      "Epoch [21/1100], Loss: 13.22656810026092\n",
      "Epoch [22/1100], Loss: 13.190324551875676\n",
      "Epoch [23/1100], Loss: 13.152159510104184\n",
      "Epoch [24/1100], Loss: 13.111605314283281\n",
      "Epoch [25/1100], Loss: 13.067998923965433\n",
      "Epoch [26/1100], Loss: 13.020628811853385\n",
      "Epoch [27/1100], Loss: 12.968623424318366\n",
      "Epoch [28/1100], Loss: 12.91120080699693\n",
      "Epoch [29/1100], Loss: 12.847906309831387\n",
      "Epoch [30/1100], Loss: 12.779233210541463\n",
      "Epoch [31/1100], Loss: 12.707439152831341\n",
      "Epoch [32/1100], Loss: 12.637003706018959\n",
      "Epoch [33/1100], Loss: 12.573517436450857\n",
      "Epoch [34/1100], Loss: 12.520352264117037\n",
      "Epoch [35/1100], Loss: 12.475705954439263\n",
      "Epoch [36/1100], Loss: 12.434300785973392\n",
      "Epoch [37/1100], Loss: 12.392243154911739\n",
      "Epoch [38/1100], Loss: 12.34928709828273\n",
      "Epoch [39/1100], Loss: 12.306888723516977\n",
      "Epoch [40/1100], Loss: 12.265963836864103\n",
      "Epoch [41/1100], Loss: 12.226383035677145\n",
      "Epoch [42/1100], Loss: 12.187547127450898\n",
      "Epoch [43/1100], Loss: 12.148892587805904\n",
      "Epoch [44/1100], Loss: 12.110114610587516\n",
      "Epoch [45/1100], Loss: 12.071159473256785\n",
      "Epoch [46/1100], Loss: 12.032053803537792\n",
      "Epoch [47/1100], Loss: 11.992853893169467\n",
      "Epoch [48/1100], Loss: 11.953649765761838\n",
      "Epoch [49/1100], Loss: 11.914489405213772\n",
      "Epoch [50/1100], Loss: 11.875383737264201\n",
      "Epoch [51/1100], Loss: 11.836373702157289\n",
      "Epoch [52/1100], Loss: 11.797471704625877\n",
      "Epoch [53/1100], Loss: 11.758656655150844\n",
      "Epoch [54/1100], Loss: 11.719938708863992\n",
      "Epoch [55/1100], Loss: 11.681325740839384\n",
      "Epoch [56/1100], Loss: 11.642792008795368\n",
      "Epoch [57/1100], Loss: 11.604325925318335\n",
      "Epoch [58/1100], Loss: 11.565933368654441\n",
      "Epoch [59/1100], Loss: 11.527612242078249\n",
      "Epoch [60/1100], Loss: 11.489324945436238\n",
      "Epoch [61/1100], Loss: 11.451092937993053\n",
      "Epoch [62/1100], Loss: 11.412906100836608\n",
      "Epoch [63/1100], Loss: 11.374774965152028\n",
      "Epoch [64/1100], Loss: 11.33668311998963\n",
      "Epoch [65/1100], Loss: 11.298635403803928\n",
      "Epoch [66/1100], Loss: 11.260648847803168\n",
      "Epoch [67/1100], Loss: 11.22268843078291\n",
      "Epoch [68/1100], Loss: 11.184779104596146\n",
      "Epoch [69/1100], Loss: 11.146921154719166\n",
      "Epoch [70/1100], Loss: 11.109088175343459\n",
      "Epoch [71/1100], Loss: 11.071302035881672\n",
      "Epoch [72/1100], Loss: 11.033538599529493\n",
      "Epoch [73/1100], Loss: 10.995803694469942\n",
      "Epoch [74/1100], Loss: 10.958087333068761\n",
      "Epoch [75/1100], Loss: 10.920398029586067\n",
      "Epoch [76/1100], Loss: 10.882720945265646\n",
      "Epoch [77/1100], Loss: 10.845053755999288\n",
      "Epoch [78/1100], Loss: 10.807398446360821\n",
      "Epoch [79/1100], Loss: 10.769746970672713\n",
      "Epoch [80/1100], Loss: 10.732086402201276\n",
      "Epoch [81/1100], Loss: 10.694406572490152\n",
      "Epoch [82/1100], Loss: 10.65670946620321\n",
      "Epoch [83/1100], Loss: 10.618981620472368\n",
      "Epoch [84/1100], Loss: 10.581222528770013\n",
      "Epoch [85/1100], Loss: 10.543400839515016\n",
      "Epoch [86/1100], Loss: 10.505534908328627\n",
      "Epoch [87/1100], Loss: 10.467601323218332\n",
      "Epoch [88/1100], Loss: 10.429584585015618\n",
      "Epoch [89/1100], Loss: 10.391467827945235\n",
      "Epoch [90/1100], Loss: 10.353243200217548\n",
      "Epoch [91/1100], Loss: 10.314902641660865\n",
      "Epoch [92/1100], Loss: 10.27640018270722\n",
      "Epoch [93/1100], Loss: 10.237752854854989\n",
      "Epoch [94/1100], Loss: 10.198937075194408\n",
      "Epoch [95/1100], Loss: 10.1599245117186\n",
      "Epoch [96/1100], Loss: 10.120701735876537\n",
      "Epoch [97/1100], Loss: 10.081273212957058\n",
      "Epoch [98/1100], Loss: 10.041600503045629\n",
      "Epoch [99/1100], Loss: 10.001706959345029\n",
      "Epoch [100/1100], Loss: 9.961574048653347\n",
      "Epoch [101/1100], Loss: 9.921212651972382\n",
      "Epoch [102/1100], Loss: 9.88065672718949\n",
      "Epoch [103/1100], Loss: 9.839930069621914\n",
      "Epoch [104/1100], Loss: 9.799067257714341\n",
      "Epoch [105/1100], Loss: 9.758126607091981\n",
      "Epoch [106/1100], Loss: 9.717168527047761\n",
      "Epoch [107/1100], Loss: 9.67627023062687\n",
      "Epoch [108/1100], Loss: 9.635500939763006\n",
      "Epoch [109/1100], Loss: 9.594921984789835\n",
      "Epoch [110/1100], Loss: 9.554583508706855\n",
      "Epoch [111/1100], Loss: 9.514555948815541\n",
      "Epoch [112/1100], Loss: 9.47484752336186\n",
      "Epoch [113/1100], Loss: 9.435501430566092\n",
      "Epoch [114/1100], Loss: 9.396520959773625\n",
      "Epoch [115/1100], Loss: 9.357881069518044\n",
      "Epoch [116/1100], Loss: 9.31958534810201\n",
      "Epoch [117/1100], Loss: 9.281615643871191\n",
      "Epoch [118/1100], Loss: 9.243944429999829\n",
      "Epoch [119/1100], Loss: 9.206547574479373\n",
      "Epoch [120/1100], Loss: 9.16940379189873\n",
      "Epoch [121/1100], Loss: 9.132491105263398\n",
      "Epoch [122/1100], Loss: 9.095785451487245\n",
      "Epoch [123/1100], Loss: 9.059283995762598\n",
      "Epoch [124/1100], Loss: 9.022945290315874\n",
      "Epoch [125/1100], Loss: 8.986793429355203\n",
      "Epoch [126/1100], Loss: 8.950789897954564\n",
      "Epoch [127/1100], Loss: 8.914932875920385\n",
      "Epoch [128/1100], Loss: 8.87921104207362\n",
      "Epoch [129/1100], Loss: 8.843619024046347\n",
      "Epoch [130/1100], Loss: 8.80814996871959\n",
      "Epoch [131/1100], Loss: 8.772792649222538\n",
      "Epoch [132/1100], Loss: 8.737553929638125\n",
      "Epoch [133/1100], Loss: 8.702425497118384\n",
      "Epoch [134/1100], Loss: 8.667391448377202\n",
      "Epoch [135/1100], Loss: 8.632465002930985\n",
      "Epoch [136/1100], Loss: 8.597651288489942\n",
      "Epoch [137/1100], Loss: 8.56292270684844\n",
      "Epoch [138/1100], Loss: 8.528287276084484\n",
      "Epoch [139/1100], Loss: 8.493758313401486\n",
      "Epoch [140/1100], Loss: 8.45931329915993\n",
      "Epoch [141/1100], Loss: 8.42496776818507\n",
      "Epoch [142/1100], Loss: 8.39070614193406\n",
      "Epoch [143/1100], Loss: 8.356542450030247\n",
      "Epoch [144/1100], Loss: 8.322473769556382\n",
      "Epoch [145/1100], Loss: 8.28848702243522\n",
      "Epoch [146/1100], Loss: 8.254598681604875\n",
      "Epoch [147/1100], Loss: 8.220792760863333\n",
      "Epoch [148/1100], Loss: 8.187073256799977\n",
      "Epoch [149/1100], Loss: 8.153453130074922\n",
      "Epoch [150/1100], Loss: 8.119919632833444\n",
      "Epoch [151/1100], Loss: 8.08646729561815\n",
      "Epoch [152/1100], Loss: 8.053106313735043\n",
      "Epoch [153/1100], Loss: 8.019833867652778\n",
      "Epoch [154/1100], Loss: 7.986640534712933\n",
      "Epoch [155/1100], Loss: 7.953545278242018\n",
      "Epoch [156/1100], Loss: 7.920541284785031\n",
      "Epoch [157/1100], Loss: 7.8876183688171295\n",
      "Epoch [158/1100], Loss: 7.854775499020889\n",
      "Epoch [159/1100], Loss: 7.82202962374231\n",
      "Epoch [160/1100], Loss: 7.789363301212688\n",
      "Epoch [161/1100], Loss: 7.756793709808335\n",
      "Epoch [162/1100], Loss: 7.724304122692956\n",
      "Epoch [163/1100], Loss: 7.69189930556422\n",
      "Epoch [164/1100], Loss: 7.6595856751946485\n",
      "Epoch [165/1100], Loss: 7.627351064881623\n",
      "Epoch [166/1100], Loss: 7.595211674873553\n",
      "Epoch [167/1100], Loss: 7.563151987488709\n",
      "Epoch [168/1100], Loss: 7.531182741880912\n",
      "Epoch [169/1100], Loss: 7.499297455005944\n",
      "Epoch [170/1100], Loss: 7.467506387295089\n",
      "Epoch [171/1100], Loss: 7.435794751197136\n",
      "Epoch [172/1100], Loss: 7.404173002686093\n",
      "Epoch [173/1100], Loss: 7.372628747737508\n",
      "Epoch [174/1100], Loss: 7.34117916262494\n",
      "Epoch [175/1100], Loss: 7.309813224398795\n",
      "Epoch [176/1100], Loss: 7.278531421849266\n",
      "Epoch [177/1100], Loss: 7.247337820186658\n",
      "Epoch [178/1100], Loss: 7.2162264366625095\n",
      "Epoch [179/1100], Loss: 7.185209162591036\n",
      "Epoch [180/1100], Loss: 7.154275023817945\n",
      "Epoch [181/1100], Loss: 7.12341376847985\n",
      "Epoch [182/1100], Loss: 7.092655224279952\n",
      "Epoch [183/1100], Loss: 7.061979060193607\n",
      "Epoch [184/1100], Loss: 7.031376214461716\n",
      "Epoch [185/1100], Loss: 7.000870102621093\n",
      "Epoch [186/1100], Loss: 6.970451126936041\n",
      "Epoch [187/1100], Loss: 6.940109062922829\n",
      "Epoch [188/1100], Loss: 6.909859331255575\n",
      "Epoch [189/1100], Loss: 6.879691271024285\n",
      "Epoch [190/1100], Loss: 6.849615344673339\n",
      "Epoch [191/1100], Loss: 6.819615994285641\n",
      "Epoch [192/1100], Loss: 6.7897128256418\n",
      "Epoch [193/1100], Loss: 6.75988559047164\n",
      "Epoch [194/1100], Loss: 6.730149737927604\n",
      "Epoch [195/1100], Loss: 6.700499073271203\n",
      "Epoch [196/1100], Loss: 6.670920413587737\n",
      "Epoch [197/1100], Loss: 6.6414324138613665\n",
      "Epoch [198/1100], Loss: 6.612039591707116\n",
      "Epoch [199/1100], Loss: 6.582722204017045\n",
      "Epoch [200/1100], Loss: 6.553490354615178\n",
      "Epoch [201/1100], Loss: 6.524343299535758\n",
      "Epoch [202/1100], Loss: 6.495285633093772\n",
      "Epoch [203/1100], Loss: 6.4663087770795755\n",
      "Epoch [204/1100], Loss: 6.437416942066193\n",
      "Epoch [205/1100], Loss: 6.408613761451306\n",
      "Epoch [206/1100], Loss: 6.3798903529934705\n",
      "Epoch [207/1100], Loss: 6.351256318525884\n",
      "Epoch [208/1100], Loss: 6.322710796730689\n",
      "Epoch [209/1100], Loss: 6.294239692259907\n",
      "Epoch [210/1100], Loss: 6.265857648346582\n",
      "Epoch [211/1100], Loss: 6.237558603598018\n",
      "Epoch [212/1100], Loss: 6.209338885598527\n",
      "Epoch [213/1100], Loss: 6.181211976778286\n",
      "Epoch [214/1100], Loss: 6.153163385924927\n",
      "Epoch [215/1100], Loss: 6.125198456642465\n",
      "Epoch [216/1100], Loss: 6.0973252976966705\n",
      "Epoch [217/1100], Loss: 6.0695260561542455\n",
      "Epoch [218/1100], Loss: 6.041818288475952\n",
      "Epoch [219/1100], Loss: 6.014184328270858\n",
      "Epoch [220/1100], Loss: 5.986641730494057\n",
      "Epoch [221/1100], Loss: 5.95917676286831\n",
      "Epoch [222/1100], Loss: 5.931803925970144\n",
      "Epoch [223/1100], Loss: 5.904508409455957\n",
      "Epoch [224/1100], Loss: 5.877298221606452\n",
      "Epoch [225/1100], Loss: 5.850170316744197\n",
      "Epoch [226/1100], Loss: 5.823128508475293\n",
      "Epoch [227/1100], Loss: 5.796163909356437\n",
      "Epoch [228/1100], Loss: 5.769289292682743\n",
      "Epoch [229/1100], Loss: 5.742496100559947\n",
      "Epoch [230/1100], Loss: 5.71578773270403\n",
      "Epoch [231/1100], Loss: 5.68915228138394\n",
      "Epoch [232/1100], Loss: 5.662606802922255\n",
      "Epoch [233/1100], Loss: 5.6361448182960885\n",
      "Epoch [234/1100], Loss: 5.609759349887099\n",
      "Epoch [235/1100], Loss: 5.583458900438927\n",
      "Epoch [236/1100], Loss: 5.557242969756771\n",
      "Epoch [237/1100], Loss: 5.531106977767195\n",
      "Epoch [238/1100], Loss: 5.505055708845248\n",
      "Epoch [239/1100], Loss: 5.479084173040292\n",
      "Epoch [240/1100], Loss: 5.453199484495826\n",
      "Epoch [241/1100], Loss: 5.427391165436575\n",
      "Epoch [242/1100], Loss: 5.401661989738386\n",
      "Epoch [243/1100], Loss: 5.376024998752655\n",
      "Epoch [244/1100], Loss: 5.350457921879752\n",
      "Epoch [245/1100], Loss: 5.324982958849432\n",
      "Epoch [246/1100], Loss: 5.299587468382242\n",
      "Epoch [247/1100], Loss: 5.274270043771594\n",
      "Epoch [248/1100], Loss: 5.249034483861578\n",
      "Epoch [249/1100], Loss: 5.223886441965078\n",
      "Epoch [250/1100], Loss: 5.198817083665972\n",
      "Epoch [251/1100], Loss: 5.1738205390361145\n",
      "Epoch [252/1100], Loss: 5.1489149809553965\n",
      "Epoch [253/1100], Loss: 5.124086484649979\n",
      "Epoch [254/1100], Loss: 5.099340954004447\n",
      "Epoch [255/1100], Loss: 5.074672096762697\n",
      "Epoch [256/1100], Loss: 5.0500849724667205\n",
      "Epoch [257/1100], Loss: 5.025583091507542\n",
      "Epoch [258/1100], Loss: 5.0011629573830305\n",
      "Epoch [259/1100], Loss: 4.976815005098615\n",
      "Epoch [260/1100], Loss: 4.952552175480605\n",
      "Epoch [261/1100], Loss: 4.928369597452729\n",
      "Epoch [262/1100], Loss: 4.9042630499588995\n",
      "Epoch [263/1100], Loss: 4.880238284193183\n",
      "Epoch [264/1100], Loss: 4.856297278337479\n",
      "Epoch [265/1100], Loss: 4.832431965227443\n",
      "Epoch [266/1100], Loss: 4.808646622586821\n",
      "Epoch [267/1100], Loss: 4.784945405466715\n",
      "Epoch [268/1100], Loss: 4.761319227271997\n",
      "Epoch [269/1100], Loss: 4.737772694231353\n",
      "Epoch [270/1100], Loss: 4.714301200191585\n",
      "Epoch [271/1100], Loss: 4.690916494158046\n",
      "Epoch [272/1100], Loss: 4.6676126099130215\n",
      "Epoch [273/1100], Loss: 4.644382274058671\n",
      "Epoch [274/1100], Loss: 4.621234142099638\n",
      "Epoch [275/1100], Loss: 4.5981526076668615\n",
      "Epoch [276/1100], Loss: 4.575161529302477\n",
      "Epoch [277/1100], Loss: 4.5522529369045515\n",
      "Epoch [278/1100], Loss: 4.529414283965934\n",
      "Epoch [279/1100], Loss: 4.506653691476458\n",
      "Epoch [280/1100], Loss: 4.483978607976724\n",
      "Epoch [281/1100], Loss: 4.461376459169514\n",
      "Epoch [282/1100], Loss: 4.438848070189124\n",
      "Epoch [283/1100], Loss: 4.416405344757777\n",
      "Epoch [284/1100], Loss: 4.3940430314996775\n",
      "Epoch [285/1100], Loss: 4.371750020608488\n",
      "Epoch [286/1100], Loss: 4.349538211085928\n",
      "Epoch [287/1100], Loss: 4.327406178783576\n",
      "Epoch [288/1100], Loss: 4.305346161026364\n",
      "Epoch [289/1100], Loss: 4.283367461932357\n",
      "Epoch [290/1100], Loss: 4.261467770165382\n",
      "Epoch [291/1100], Loss: 4.239641150810712\n",
      "Epoch [292/1100], Loss: 4.217893699424394\n",
      "Epoch [293/1100], Loss: 4.196217258633851\n",
      "Epoch [294/1100], Loss: 4.1746247146459154\n",
      "Epoch [295/1100], Loss: 4.1531076396615845\n",
      "Epoch [296/1100], Loss: 4.131669218997786\n",
      "Epoch [297/1100], Loss: 4.110298797863834\n",
      "Epoch [298/1100], Loss: 4.089013855311578\n",
      "Epoch [299/1100], Loss: 4.067803457322043\n",
      "Epoch [300/1100], Loss: 4.046663890766013\n",
      "Epoch [301/1100], Loss: 4.025606631706069\n",
      "Epoch [302/1100], Loss: 4.004615706017148\n",
      "Epoch [303/1100], Loss: 3.983706345638211\n",
      "Epoch [304/1100], Loss: 3.9628749023879664\n",
      "Epoch [305/1100], Loss: 3.9421167288730885\n",
      "Epoch [306/1100], Loss: 3.921436288647101\n",
      "Epoch [307/1100], Loss: 3.900828502775312\n",
      "Epoch [308/1100], Loss: 3.8802946409734886\n",
      "Epoch [309/1100], Loss: 3.859833597565739\n",
      "Epoch [310/1100], Loss: 3.839453230994195\n",
      "Epoch [311/1100], Loss: 3.819148167772255\n",
      "Epoch [312/1100], Loss: 3.7989166294814822\n",
      "Epoch [313/1100], Loss: 3.778753186281392\n",
      "Epoch [314/1100], Loss: 3.758670084813275\n",
      "Epoch [315/1100], Loss: 3.7386586567927225\n",
      "Epoch [316/1100], Loss: 3.7187267232875456\n",
      "Epoch [317/1100], Loss: 3.6988587989562802\n",
      "Epoch [318/1100], Loss: 3.6790696739817577\n",
      "Epoch [319/1100], Loss: 3.659352245495029\n",
      "Epoch [320/1100], Loss: 3.6397135568122394\n",
      "Epoch [321/1100], Loss: 3.6201422302578976\n",
      "Epoch [322/1100], Loss: 3.600652649845415\n",
      "Epoch [323/1100], Loss: 3.581233237227025\n",
      "Epoch [324/1100], Loss: 3.5618779418193753\n",
      "Epoch [325/1100], Loss: 3.5426072279663003\n",
      "Epoch [326/1100], Loss: 3.5234072171233493\n",
      "Epoch [327/1100], Loss: 3.504277146827917\n",
      "Epoch [328/1100], Loss: 3.4852130490080526\n",
      "Epoch [329/1100], Loss: 3.4662330174789986\n",
      "Epoch [330/1100], Loss: 3.4473194297879672\n",
      "Epoch [331/1100], Loss: 3.4284789455152804\n",
      "Epoch [332/1100], Loss: 3.409707288149775\n",
      "Epoch [333/1100], Loss: 3.3910086338048586\n",
      "Epoch [334/1100], Loss: 3.372385878477189\n",
      "Epoch [335/1100], Loss: 3.353835395771057\n",
      "Epoch [336/1100], Loss: 3.3353538275280243\n",
      "Epoch [337/1100], Loss: 3.3169439981002142\n",
      "Epoch [338/1100], Loss: 3.298609761199259\n",
      "Epoch [339/1100], Loss: 3.2803397722473164\n",
      "Epoch [340/1100], Loss: 3.2621479260787964\n",
      "Epoch [341/1100], Loss: 3.2440179013310626\n",
      "Epoch [342/1100], Loss: 3.225965536899821\n",
      "Epoch [343/1100], Loss: 3.207980809732362\n",
      "Epoch [344/1100], Loss: 3.1900663576379884\n",
      "Epoch [345/1100], Loss: 3.172222982759422\n",
      "Epoch [346/1100], Loss: 3.154443087640402\n",
      "Epoch [347/1100], Loss: 3.1367436922491834\n",
      "Epoch [348/1100], Loss: 3.119110909503661\n",
      "Epoch [349/1100], Loss: 3.1015511677462655\n",
      "Epoch [350/1100], Loss: 3.084054724681664\n",
      "Epoch [351/1100], Loss: 3.0666345536194513\n",
      "Epoch [352/1100], Loss: 3.0492769615975703\n",
      "Epoch [353/1100], Loss: 3.0319927273380927\n",
      "Epoch [354/1100], Loss: 3.0147801647872257\n",
      "Epoch [355/1100], Loss: 2.9976298158690042\n",
      "Epoch [356/1100], Loss: 2.9805513369201435\n",
      "Epoch [357/1100], Loss: 2.963544959204228\n",
      "Epoch [358/1100], Loss: 2.9466066183053954\n",
      "Epoch [359/1100], Loss: 2.929730903515974\n",
      "Epoch [360/1100], Loss: 2.9129322508345012\n",
      "Epoch [361/1100], Loss: 2.896195105835659\n",
      "Epoch [362/1100], Loss: 2.879525128513933\n",
      "Epoch [363/1100], Loss: 2.862926443960532\n",
      "Epoch [364/1100], Loss: 2.8463950827390363\n",
      "Epoch [365/1100], Loss: 2.8299244009185713\n",
      "Epoch [366/1100], Loss: 2.813533676793668\n",
      "Epoch [367/1100], Loss: 2.797199891054561\n",
      "Epoch [368/1100], Loss: 2.7809392636556822\n",
      "Epoch [369/1100], Loss: 2.764742022613291\n",
      "Epoch [370/1100], Loss: 2.748610969240872\n",
      "Epoch [371/1100], Loss: 2.7325557861840934\n",
      "Epoch [372/1100], Loss: 2.7165600664577596\n",
      "Epoch [373/1100], Loss: 2.7006301100745986\n",
      "Epoch [374/1100], Loss: 2.684765693674308\n",
      "Epoch [375/1100], Loss: 2.6689701640900694\n",
      "Epoch [376/1100], Loss: 2.6532368232910812\n",
      "Epoch [377/1100], Loss: 2.637574494416185\n",
      "Epoch [378/1100], Loss: 2.621977465336613\n",
      "Epoch [379/1100], Loss: 2.606444653696826\n",
      "Epoch [380/1100], Loss: 2.5909767826308325\n",
      "Epoch [381/1100], Loss: 2.575573258528493\n",
      "Epoch [382/1100], Loss: 2.560237391964847\n",
      "Epoch [383/1100], Loss: 2.544962430608848\n",
      "Epoch [384/1100], Loss: 2.529760714563963\n",
      "Epoch [385/1100], Loss: 2.514612654398661\n",
      "Epoch [386/1100], Loss: 2.4995350985886944\n",
      "Epoch [387/1100], Loss: 2.4845211448737246\n",
      "Epoch [388/1100], Loss: 2.4695731152517055\n",
      "Epoch [389/1100], Loss: 2.4546850097578954\n",
      "Epoch [390/1100], Loss: 2.439862434572433\n",
      "Epoch [391/1100], Loss: 2.4251062038520104\n",
      "Epoch [392/1100], Loss: 2.4104122934927545\n",
      "Epoch [393/1100], Loss: 2.3957841149708656\n",
      "Epoch [394/1100], Loss: 2.3812148097576937\n",
      "Epoch [395/1100], Loss: 2.366710699123587\n",
      "Epoch [396/1100], Loss: 2.352271373209078\n",
      "Epoch [397/1100], Loss: 2.337896383311545\n",
      "Epoch [398/1100], Loss: 2.3235805687800166\n",
      "Epoch [399/1100], Loss: 2.309322585013433\n",
      "Epoch [400/1100], Loss: 2.2951344411849277\n",
      "Epoch [401/1100], Loss: 2.2810079359364863\n",
      "Epoch [402/1100], Loss: 2.266942076332498\n",
      "Epoch [403/1100], Loss: 2.2529398309998214\n",
      "Epoch [404/1100], Loss: 2.239003744638694\n",
      "Epoch [405/1100], Loss: 2.225119563889166\n",
      "Epoch [406/1100], Loss: 2.2112984653031162\n",
      "Epoch [407/1100], Loss: 2.1975456223519814\n",
      "Epoch [408/1100], Loss: 2.1838525469377146\n",
      "Epoch [409/1100], Loss: 2.170216504410064\n",
      "Epoch [410/1100], Loss: 2.1566459325295\n",
      "Epoch [411/1100], Loss: 2.1431344327977513\n",
      "Epoch [412/1100], Loss: 2.129681849450435\n",
      "Epoch [413/1100], Loss: 2.116291419750496\n",
      "Epoch [414/1100], Loss: 2.1029597364631627\n",
      "Epoch [415/1100], Loss: 2.0896894172255998\n",
      "Epoch [416/1100], Loss: 2.076480516176389\n",
      "Epoch [417/1100], Loss: 2.0633241251207437\n",
      "Epoch [418/1100], Loss: 2.0502399372273885\n",
      "Epoch [419/1100], Loss: 2.0372058926498084\n",
      "Epoch [420/1100], Loss: 2.024239623555559\n",
      "Epoch [421/1100], Loss: 2.0113257469820383\n",
      "Epoch [422/1100], Loss: 1.9984725104170593\n",
      "Epoch [423/1100], Loss: 1.985679771873265\n",
      "Epoch [424/1100], Loss: 1.9729435839346934\n",
      "Epoch [425/1100], Loss: 1.9602722974859716\n",
      "Epoch [426/1100], Loss: 1.947650161573847\n",
      "Epoch [427/1100], Loss: 1.935092202820897\n",
      "Epoch [428/1100], Loss: 1.9225885914820537\n",
      "Epoch [429/1100], Loss: 1.9101435432330618\n",
      "Epoch [430/1100], Loss: 1.8977603372077283\n",
      "Epoch [431/1100], Loss: 1.8854335152000203\n",
      "Epoch [432/1100], Loss: 1.873166634932204\n",
      "Epoch [433/1100], Loss: 1.8609509029249693\n",
      "Epoch [434/1100], Loss: 1.8487982665849358\n",
      "Epoch [435/1100], Loss: 1.8367039369768463\n",
      "Epoch [436/1100], Loss: 1.8246616463934515\n",
      "Epoch [437/1100], Loss: 1.81268001237936\n",
      "Epoch [438/1100], Loss: 1.8007529986118698\n",
      "Epoch [439/1100], Loss: 1.7888804895997055\n",
      "Epoch [440/1100], Loss: 1.777063098277722\n",
      "Epoch [441/1100], Loss: 1.7653066594184565\n",
      "Epoch [442/1100], Loss: 1.753607724562471\n",
      "Epoch [443/1100], Loss: 1.741960002762653\n",
      "Epoch [444/1100], Loss: 1.7303690647422627\n",
      "Epoch [445/1100], Loss: 1.7188360561851823\n",
      "Epoch [446/1100], Loss: 1.7073575130636982\n",
      "Epoch [447/1100], Loss: 1.695933711916041\n",
      "Epoch [448/1100], Loss: 1.6845701367356014\n",
      "Epoch [449/1100], Loss: 1.6732539293270747\n",
      "Epoch [450/1100], Loss: 1.662000090445872\n",
      "Epoch [451/1100], Loss: 1.6507960169220155\n",
      "Epoch [452/1100], Loss: 1.6396509503201742\n",
      "Epoch [453/1100], Loss: 1.6285532472656996\n",
      "Epoch [454/1100], Loss: 1.617546182762453\n",
      "Epoch [455/1100], Loss: 1.6065662996807077\n",
      "Epoch [456/1100], Loss: 1.595759521022046\n",
      "Epoch [457/1100], Loss: 1.5850128900783602\n",
      "Epoch [458/1100], Loss: 1.5747732289455598\n",
      "Epoch [459/1100], Loss: 1.5648683511390118\n",
      "Epoch [460/1100], Loss: 1.5561258557083875\n",
      "Epoch [461/1100], Loss: 1.5464820149936713\n",
      "Epoch [462/1100], Loss: 1.535191133585613\n",
      "Epoch [463/1100], Loss: 1.5217464820598252\n",
      "Epoch [464/1100], Loss: 1.5100805443291847\n",
      "Epoch [465/1100], Loss: 1.500137487633765\n",
      "Epoch [466/1100], Loss: 1.4898806562268874\n",
      "Epoch [467/1100], Loss: 1.4792143521829075\n",
      "Epoch [468/1100], Loss: 1.4686178416141047\n",
      "Epoch [469/1100], Loss: 1.4583987857186003\n",
      "Epoch [470/1100], Loss: 1.4483066779666842\n",
      "Epoch [471/1100], Loss: 1.4380849896988366\n",
      "Epoch [472/1100], Loss: 1.4279466725765815\n",
      "Epoch [473/1100], Loss: 1.4179121491179103\n",
      "Epoch [474/1100], Loss: 1.4079266974131315\n",
      "Epoch [475/1100], Loss: 1.3980038463978417\n",
      "Epoch [476/1100], Loss: 1.3880998661561534\n",
      "Epoch [477/1100], Loss: 1.3782605631915885\n",
      "Epoch [478/1100], Loss: 1.368481254150538\n",
      "Epoch [479/1100], Loss: 1.3587447844411145\n",
      "Epoch [480/1100], Loss: 1.3490683740365057\n",
      "Epoch [481/1100], Loss: 1.3394303812974613\n",
      "Epoch [482/1100], Loss: 1.3298491971595467\n",
      "Epoch [483/1100], Loss: 1.3203186422688304\n",
      "Epoch [484/1100], Loss: 1.3108341697925425\n",
      "Epoch [485/1100], Loss: 1.301401238468543\n",
      "Epoch [486/1100], Loss: 1.292014641537719\n",
      "Epoch [487/1100], Loss: 1.2826806122566268\n",
      "Epoch [488/1100], Loss: 1.273395843116532\n",
      "Epoch [489/1100], Loss: 1.2641567856872484\n",
      "Epoch [490/1100], Loss: 1.2549697062115683\n",
      "Epoch [491/1100], Loss: 1.2458301059000974\n",
      "Epoch [492/1100], Loss: 1.2367370825845683\n",
      "Epoch [493/1100], Loss: 1.2276920323604372\n",
      "Epoch [494/1100], Loss: 1.2186968533037543\n",
      "Epoch [495/1100], Loss: 1.2097513708222323\n",
      "Epoch [496/1100], Loss: 1.2008495009740727\n",
      "Epoch [497/1100], Loss: 1.1919976450180911\n",
      "Epoch [498/1100], Loss: 1.183192709562718\n",
      "Epoch [499/1100], Loss: 1.1744328201348253\n",
      "Epoch [500/1100], Loss: 1.1657234488268386\n",
      "Epoch [501/1100], Loss: 1.1570594133866052\n",
      "Epoch [502/1100], Loss: 1.1484440038848334\n",
      "Epoch [503/1100], Loss: 1.1398751620326948\n",
      "Epoch [504/1100], Loss: 1.1313524371262247\n",
      "Epoch [505/1100], Loss: 1.122875872340046\n",
      "Epoch [506/1100], Loss: 1.1144451354850844\n",
      "Epoch [507/1100], Loss: 1.106062332176407\n",
      "Epoch [508/1100], Loss: 1.0977211484023428\n",
      "Epoch [509/1100], Loss: 1.0894295268985843\n",
      "Epoch [510/1100], Loss: 1.0811832012900595\n",
      "Epoch [511/1100], Loss: 1.0729822268478983\n",
      "Epoch [512/1100], Loss: 1.064825647984435\n",
      "Epoch [513/1100], Loss: 1.0567124772408079\n",
      "Epoch [514/1100], Loss: 1.0486476280259467\n",
      "Epoch [515/1100], Loss: 1.0406256853248124\n",
      "Epoch [516/1100], Loss: 1.0326538033250472\n",
      "Epoch [517/1100], Loss: 1.024722299574023\n",
      "Epoch [518/1100], Loss: 1.0168324109235982\n",
      "Epoch [519/1100], Loss: 1.0089908532902427\n",
      "Epoch [520/1100], Loss: 1.0011927170926356\n",
      "Epoch [521/1100], Loss: 0.9934365490810251\n",
      "Epoch [522/1100], Loss: 0.9857272691647267\n",
      "Epoch [523/1100], Loss: 0.9780591793705753\n",
      "Epoch [524/1100], Loss: 0.9704365100960786\n",
      "Epoch [525/1100], Loss: 0.9628605081447859\n",
      "Epoch [526/1100], Loss: 0.955324964677402\n",
      "Epoch [527/1100], Loss: 0.9478305074610489\n",
      "Epoch [528/1100], Loss: 0.9403784352582534\n",
      "Epoch [529/1100], Loss: 0.9329727013921456\n",
      "Epoch [530/1100], Loss: 0.9256102105646846\n",
      "Epoch [531/1100], Loss: 0.918286764682307\n",
      "Epoch [532/1100], Loss: 0.9110094491063592\n",
      "Epoch [533/1100], Loss: 0.9037741686852314\n",
      "Epoch [534/1100], Loss: 0.8965777291525683\n",
      "Epoch [535/1100], Loss: 0.8894285095339001\n",
      "Epoch [536/1100], Loss: 0.8823155148513706\n",
      "Epoch [537/1100], Loss: 0.8752580718382887\n",
      "Epoch [538/1100], Loss: 0.8682265732904852\n",
      "Epoch [539/1100], Loss: 0.8612818715155299\n",
      "Epoch [540/1100], Loss: 0.8543596350027656\n",
      "Epoch [541/1100], Loss: 0.8476489191234577\n",
      "Epoch [542/1100], Loss: 0.8410775583215582\n",
      "Epoch [543/1100], Loss: 0.8353390043484978\n",
      "Epoch [544/1100], Loss: 0.8304709184085368\n",
      "Epoch [545/1100], Loss: 0.8274645682695336\n",
      "Epoch [546/1100], Loss: 0.8217607882688753\n",
      "Epoch [547/1100], Loss: 0.8119438149187772\n",
      "Epoch [548/1100], Loss: 0.80081155867083\n",
      "Epoch [549/1100], Loss: 0.7940266296245682\n",
      "Epoch [550/1100], Loss: 0.7886156213653521\n",
      "Epoch [551/1100], Loss: 0.7814606117462972\n",
      "Epoch [552/1100], Loss: 0.7742664135521409\n",
      "Epoch [553/1100], Loss: 0.7679350064718165\n",
      "Epoch [554/1100], Loss: 0.7616823669814039\n",
      "Epoch [555/1100], Loss: 0.7552385672179298\n",
      "Epoch [556/1100], Loss: 0.7487947562424324\n",
      "Epoch [557/1100], Loss: 0.742548628415534\n",
      "Epoch [558/1100], Loss: 0.7363792064716108\n",
      "Epoch [559/1100], Loss: 0.7301517072373827\n",
      "Epoch [560/1100], Loss: 0.723989392607109\n",
      "Epoch [561/1100], Loss: 0.7178961948384313\n",
      "Epoch [562/1100], Loss: 0.7118272672541934\n",
      "Epoch [563/1100], Loss: 0.7058045677367772\n",
      "Epoch [564/1100], Loss: 0.6998060584006112\n",
      "Epoch [565/1100], Loss: 0.6938525021853366\n",
      "Epoch [566/1100], Loss: 0.6879448252238944\n",
      "Epoch [567/1100], Loss: 0.6820665031091266\n",
      "Epoch [568/1100], Loss: 0.676230258913165\n",
      "Epoch [569/1100], Loss: 0.6704296364246147\n",
      "Epoch [570/1100], Loss: 0.6646660154804067\n",
      "Epoch [571/1100], Loss: 0.658943453445545\n",
      "Epoch [572/1100], Loss: 0.6532536815975618\n",
      "Epoch [573/1100], Loss: 0.6476036564947663\n",
      "Epoch [574/1100], Loss: 0.6419879876195864\n",
      "Epoch [575/1100], Loss: 0.6364098831518845\n",
      "Epoch [576/1100], Loss: 0.6308676814433056\n",
      "Epoch [577/1100], Loss: 0.625364002022252\n",
      "Epoch [578/1100], Loss: 0.6198958627674074\n",
      "Epoch [579/1100], Loss: 0.6144630884173239\n",
      "Epoch [580/1100], Loss: 0.609066103047553\n",
      "Epoch [581/1100], Loss: 0.6037051292096294\n",
      "Epoch [582/1100], Loss: 0.5983810866966905\n",
      "Epoch [583/1100], Loss: 0.5930922712004758\n",
      "Epoch [584/1100], Loss: 0.5878372903689524\n",
      "Epoch [585/1100], Loss: 0.5826203095639357\n",
      "Epoch [586/1100], Loss: 0.5774381315723076\n",
      "Epoch [587/1100], Loss: 0.5722906471855822\n",
      "Epoch [588/1100], Loss: 0.5671779042970684\n",
      "Epoch [589/1100], Loss: 0.5620992143312833\n",
      "Epoch [590/1100], Loss: 0.5570549584992932\n",
      "Epoch [591/1100], Loss: 0.552047751316934\n",
      "Epoch [592/1100], Loss: 0.5470731238494864\n",
      "Epoch [593/1100], Loss: 0.542134846464478\n",
      "Epoch [594/1100], Loss: 0.5372287944855998\n",
      "Epoch [595/1100], Loss: 0.5323563567108067\n",
      "Epoch [596/1100], Loss: 0.5275197543180639\n",
      "Epoch [597/1100], Loss: 0.5227151343044625\n",
      "Epoch [598/1100], Loss: 0.5179461160741994\n",
      "Epoch [599/1100], Loss: 0.5132099904642473\n",
      "Epoch [600/1100], Loss: 0.5085076998514069\n",
      "Epoch [601/1100], Loss: 0.5038368601290131\n",
      "Epoch [602/1100], Loss: 0.49920231018273853\n",
      "Epoch [603/1100], Loss: 0.49459714970384994\n",
      "Epoch [604/1100], Loss: 0.4900267396292861\n",
      "Epoch [605/1100], Loss: 0.48548950580902783\n",
      "Epoch [606/1100], Loss: 0.4809853098815893\n",
      "Epoch [607/1100], Loss: 0.4765127069042592\n",
      "Epoch [608/1100], Loss: 0.4720716938484202\n",
      "Epoch [609/1100], Loss: 0.4676642636104589\n",
      "Epoch [610/1100], Loss: 0.4632879279017743\n",
      "Epoch [611/1100], Loss: 0.4589439493730083\n",
      "Epoch [612/1100], Loss: 0.4546320390620622\n",
      "Epoch [613/1100], Loss: 0.4503519303361827\n",
      "Epoch [614/1100], Loss: 0.4461036585346392\n",
      "Epoch [615/1100], Loss: 0.4418868410432424\n",
      "Epoch [616/1100], Loss: 0.4376991425525034\n",
      "Epoch [617/1100], Loss: 0.43354363770237114\n",
      "Epoch [618/1100], Loss: 0.4294193613823154\n",
      "Epoch [619/1100], Loss: 0.4253249321882322\n",
      "Epoch [620/1100], Loss: 0.4212648092818654\n",
      "Epoch [621/1100], Loss: 0.4172326957605037\n",
      "Epoch [622/1100], Loss: 0.4132315792742247\n",
      "Epoch [623/1100], Loss: 0.40926010023758863\n",
      "Epoch [624/1100], Loss: 0.4053203454387244\n",
      "Epoch [625/1100], Loss: 0.40140909374622424\n",
      "Epoch [626/1100], Loss: 0.3975281194943818\n",
      "Epoch [627/1100], Loss: 0.3936772800898325\n",
      "Epoch [628/1100], Loss: 0.38985427629631886\n",
      "Epoch [629/1100], Loss: 0.3860611708414581\n",
      "Epoch [630/1100], Loss: 0.3823010606947719\n",
      "Epoch [631/1100], Loss: 0.3785661985095885\n",
      "Epoch [632/1100], Loss: 0.37486610611813376\n",
      "Epoch [633/1100], Loss: 0.3711877230080063\n",
      "Epoch [634/1100], Loss: 0.367553939071513\n",
      "Epoch [635/1100], Loss: 0.36393592265085317\n",
      "Epoch [636/1100], Loss: 0.36039629914739635\n",
      "Epoch [637/1100], Loss: 0.3568880606617313\n",
      "Epoch [638/1100], Loss: 0.353610252773251\n",
      "Epoch [639/1100], Loss: 0.3505797305442684\n",
      "Epoch [640/1100], Loss: 0.3485884959955001\n",
      "Epoch [641/1100], Loss: 0.3478509275446413\n",
      "Epoch [642/1100], Loss: 0.34910238818793005\n",
      "Epoch [643/1100], Loss: 0.3463432628486771\n",
      "Epoch [644/1100], Loss: 0.3383519746203092\n",
      "Epoch [645/1100], Loss: 0.3297569792921422\n",
      "Epoch [646/1100], Loss: 0.3266199634272198\n",
      "Epoch [647/1100], Loss: 0.3245736228966507\n",
      "Epoch [648/1100], Loss: 0.3203515550339944\n",
      "Epoch [649/1100], Loss: 0.3162807118442288\n",
      "Epoch [650/1100], Loss: 0.31324630481321947\n",
      "Epoch [651/1100], Loss: 0.31018954783212394\n",
      "Epoch [652/1100], Loss: 0.30686919056279294\n",
      "Epoch [653/1100], Loss: 0.3035888601917236\n",
      "Epoch [654/1100], Loss: 0.30052356357555254\n",
      "Epoch [655/1100], Loss: 0.297489791553744\n",
      "Epoch [656/1100], Loss: 0.29438058696359803\n",
      "Epoch [657/1100], Loss: 0.29134028336153506\n",
      "Epoch [658/1100], Loss: 0.28835533166784444\n",
      "Epoch [659/1100], Loss: 0.2853773175338574\n",
      "Epoch [660/1100], Loss: 0.28242865208449075\n",
      "Epoch [661/1100], Loss: 0.2794967220615945\n",
      "Epoch [662/1100], Loss: 0.2765980530678007\n",
      "Epoch [663/1100], Loss: 0.2737284385902967\n",
      "Epoch [664/1100], Loss: 0.2708762045786557\n",
      "Epoch [665/1100], Loss: 0.26805020838219207\n",
      "Epoch [666/1100], Loss: 0.26524997778528814\n",
      "Epoch [667/1100], Loss: 0.2624711590797233\n",
      "Epoch [668/1100], Loss: 0.2597208064364622\n",
      "Epoch [669/1100], Loss: 0.2569902420955259\n",
      "Epoch [670/1100], Loss: 0.254283030827537\n",
      "Epoch [671/1100], Loss: 0.2516004633891953\n",
      "Epoch [672/1100], Loss: 0.24894215149112142\n",
      "Epoch [673/1100], Loss: 0.24630613921362965\n",
      "Epoch [674/1100], Loss: 0.24369279433381053\n",
      "Epoch [675/1100], Loss: 0.2411016133839894\n",
      "Epoch [676/1100], Loss: 0.23853521848127457\n",
      "Epoch [677/1100], Loss: 0.23598974886823498\n",
      "Epoch [678/1100], Loss: 0.23346579273953694\n",
      "Epoch [679/1100], Loss: 0.2309661694200713\n",
      "Epoch [680/1100], Loss: 0.22848903208250704\n",
      "Epoch [681/1100], Loss: 0.22603268529655907\n",
      "Epoch [682/1100], Loss: 0.2235986075216374\n",
      "Epoch [683/1100], Loss: 0.22118663755190937\n",
      "Epoch [684/1100], Loss: 0.2187948982546004\n",
      "Epoch [685/1100], Loss: 0.21642523676297287\n",
      "Epoch [686/1100], Loss: 0.21407524770256714\n",
      "Epoch [687/1100], Loss: 0.21174884714969266\n",
      "Epoch [688/1100], Loss: 0.20944219260042019\n",
      "Epoch [689/1100], Loss: 0.20715839595231955\n",
      "Epoch [690/1100], Loss: 0.20489248594662968\n",
      "Epoch [691/1100], Loss: 0.2026475827062768\n",
      "Epoch [692/1100], Loss: 0.20042521354412202\n",
      "Epoch [693/1100], Loss: 0.19822029283568554\n",
      "Epoch [694/1100], Loss: 0.19603780246785618\n",
      "Epoch [695/1100], Loss: 0.19387389238295327\n",
      "Epoch [696/1100], Loss: 0.1917322178496761\n",
      "Epoch [697/1100], Loss: 0.18960911793533342\n",
      "Epoch [698/1100], Loss: 0.18750427668896918\n",
      "Epoch [699/1100], Loss: 0.18542118667505747\n",
      "Epoch [700/1100], Loss: 0.1833546724030839\n",
      "Epoch [701/1100], Loss: 0.1813077602512294\n",
      "Epoch [702/1100], Loss: 0.17928201621640483\n",
      "Epoch [703/1100], Loss: 0.17727425540942932\n",
      "Epoch [704/1100], Loss: 0.17528412036904228\n",
      "Epoch [705/1100], Loss: 0.1733146106910226\n",
      "Epoch [706/1100], Loss: 0.17136279879855465\n",
      "Epoch [707/1100], Loss: 0.1694282213084648\n",
      "Epoch [708/1100], Loss: 0.16751391024678242\n",
      "Epoch [709/1100], Loss: 0.16561685845317697\n",
      "Epoch [710/1100], Loss: 0.16373665568426077\n",
      "Epoch [711/1100], Loss: 0.16187653622569087\n",
      "Epoch [712/1100], Loss: 0.1600330326937751\n",
      "Epoch [713/1100], Loss: 0.15820627889843308\n",
      "Epoch [714/1100], Loss: 0.15639750677343045\n",
      "Epoch [715/1100], Loss: 0.15460657848984738\n",
      "Epoch [716/1100], Loss: 0.15283202983573574\n",
      "Epoch [717/1100], Loss: 0.15107660239959841\n",
      "Epoch [718/1100], Loss: 0.1493371922970823\n",
      "Epoch [719/1100], Loss: 0.1476137147806753\n",
      "Epoch [720/1100], Loss: 0.14590910223483888\n",
      "Epoch [721/1100], Loss: 0.14421866187200294\n",
      "Epoch [722/1100], Loss: 0.14254521172483692\n",
      "Epoch [723/1100], Loss: 0.14088879392261333\n",
      "Epoch [724/1100], Loss: 0.13924775160671743\n",
      "Epoch [725/1100], Loss: 0.13762190361671855\n",
      "Epoch [726/1100], Loss: 0.13601556525850356\n",
      "Epoch [727/1100], Loss: 0.13442288082751475\n",
      "Epoch [728/1100], Loss: 0.13284630825751265\n",
      "Epoch [729/1100], Loss: 0.13128491883094284\n",
      "Epoch [730/1100], Loss: 0.1297392480155395\n",
      "Epoch [731/1100], Loss: 0.1282072288027507\n",
      "Epoch [732/1100], Loss: 0.1266921402641401\n",
      "Epoch [733/1100], Loss: 0.1251930569351316\n",
      "Epoch [734/1100], Loss: 0.12370663186590036\n",
      "Epoch [735/1100], Loss: 0.12223768028911763\n",
      "Epoch [736/1100], Loss: 0.12078069445306028\n",
      "Epoch [737/1100], Loss: 0.11934135525461897\n",
      "Epoch [738/1100], Loss: 0.11791373134678906\n",
      "Epoch [739/1100], Loss: 0.11650420325895539\n",
      "Epoch [740/1100], Loss: 0.11510559676571575\n",
      "Epoch [741/1100], Loss: 0.11372918851702707\n",
      "Epoch [742/1100], Loss: 0.11236093811839964\n",
      "Epoch [743/1100], Loss: 0.11102514596495894\n",
      "Epoch [744/1100], Loss: 0.10970424136849033\n",
      "Epoch [745/1100], Loss: 0.10845769177831244\n",
      "Epoch [746/1100], Loss: 0.10727735802902316\n",
      "Epoch [747/1100], Loss: 0.106365760766721\n",
      "Epoch [748/1100], Loss: 0.10582321221954771\n",
      "Epoch [749/1100], Loss: 0.10631122394647718\n",
      "Epoch [750/1100], Loss: 0.10774331578068086\n",
      "Epoch [751/1100], Loss: 0.10984715105587384\n",
      "Epoch [752/1100], Loss: 0.10782983476019581\n",
      "Epoch [753/1100], Loss: 0.10247467179578962\n",
      "Epoch [754/1100], Loss: 0.09742463658130873\n",
      "Epoch [755/1100], Loss: 0.09619094533627504\n",
      "Epoch [756/1100], Loss: 0.09578635937418767\n",
      "Epoch [757/1100], Loss: 0.09425787328382285\n",
      "Epoch [758/1100], Loss: 0.09255452956131194\n",
      "Epoch [759/1100], Loss: 0.09116539848491811\n",
      "Epoch [760/1100], Loss: 0.09014594057771319\n",
      "Epoch [761/1100], Loss: 0.08906262409823285\n",
      "Epoch [762/1100], Loss: 0.08782358348980779\n",
      "Epoch [763/1100], Loss: 0.0867077670056915\n",
      "Epoch [764/1100], Loss: 0.08560007798678271\n",
      "Epoch [765/1100], Loss: 0.08452667935034697\n",
      "Epoch [766/1100], Loss: 0.0834818360274312\n",
      "Epoch [767/1100], Loss: 0.08239540067484086\n",
      "Epoch [768/1100], Loss: 0.08135837168339322\n",
      "Epoch [769/1100], Loss: 0.08032970385556837\n",
      "Epoch [770/1100], Loss: 0.0793044032573107\n",
      "Epoch [771/1100], Loss: 0.07830510020562542\n",
      "Epoch [772/1100], Loss: 0.07729958794175218\n",
      "Epoch [773/1100], Loss: 0.07631480847908279\n",
      "Epoch [774/1100], Loss: 0.07534155562512979\n",
      "Epoch [775/1100], Loss: 0.07437408519490418\n",
      "Epoch [776/1100], Loss: 0.073421029273959\n",
      "Epoch [777/1100], Loss: 0.0724758308890614\n",
      "Epoch [778/1100], Loss: 0.07154295826694579\n",
      "Epoch [779/1100], Loss: 0.07061956533516422\n",
      "Epoch [780/1100], Loss: 0.06970597386367672\n",
      "Epoch [781/1100], Loss: 0.06880417149227469\n",
      "Epoch [782/1100], Loss: 0.0679104664204715\n",
      "Epoch [783/1100], Loss: 0.06702788763959688\n",
      "Epoch [784/1100], Loss: 0.06615409227561031\n",
      "Epoch [785/1100], Loss: 0.06529059411377602\n",
      "Epoch [786/1100], Loss: 0.06443728959334294\n",
      "Epoch [787/1100], Loss: 0.0635923316735898\n",
      "Epoch [788/1100], Loss: 0.06275737952682903\n",
      "Epoch [789/1100], Loss: 0.06193276135496717\n",
      "Epoch [790/1100], Loss: 0.061116399092497886\n",
      "Epoch [791/1100], Loss: 0.060309393733859906\n",
      "Epoch [792/1100], Loss: 0.059511023797540474\n",
      "Epoch [793/1100], Loss: 0.058723343976055276\n",
      "Epoch [794/1100], Loss: 0.057943593544734995\n",
      "Epoch [795/1100], Loss: 0.05717293943052937\n",
      "Epoch [796/1100], Loss: 0.0564098512968485\n",
      "Epoch [797/1100], Loss: 0.05565760075160142\n",
      "Epoch [798/1100], Loss: 0.054912863017307245\n",
      "Epoch [799/1100], Loss: 0.05417590345609824\n",
      "Epoch [800/1100], Loss: 0.053449214126203515\n",
      "Epoch [801/1100], Loss: 0.0527291505684957\n",
      "Epoch [802/1100], Loss: 0.05201833602518491\n",
      "Epoch [803/1100], Loss: 0.05131583722618416\n",
      "Epoch [804/1100], Loss: 0.05062149237824087\n",
      "Epoch [805/1100], Loss: 0.04993446304274585\n",
      "Epoch [806/1100], Loss: 0.049256415155923605\n",
      "Epoch [807/1100], Loss: 0.04858617916494268\n",
      "Epoch [808/1100], Loss: 0.04792423205600471\n",
      "Epoch [809/1100], Loss: 0.04726881631182778\n",
      "Epoch [810/1100], Loss: 0.04662096817651218\n",
      "Epoch [811/1100], Loss: 0.0459819082791455\n",
      "Epoch [812/1100], Loss: 0.04535021646211135\n",
      "Epoch [813/1100], Loss: 0.04472492460831745\n",
      "Epoch [814/1100], Loss: 0.04410822405156978\n",
      "Epoch [815/1100], Loss: 0.04349888674306612\n",
      "Epoch [816/1100], Loss: 0.04289612699363943\n",
      "Epoch [817/1100], Loss: 0.04230085072691736\n",
      "Epoch [818/1100], Loss: 0.04171267181897065\n",
      "Epoch [819/1100], Loss: 0.04113109414743121\n",
      "Epoch [820/1100], Loss: 0.04055733074028467\n",
      "Epoch [821/1100], Loss: 0.039989909469341\n",
      "Epoch [822/1100], Loss: 0.039430381250440405\n",
      "Epoch [823/1100], Loss: 0.03887683198013292\n",
      "Epoch [824/1100], Loss: 0.03832970440998906\n",
      "Epoch [825/1100], Loss: 0.037789147884041085\n",
      "Epoch [826/1100], Loss: 0.03725566887646892\n",
      "Epoch [827/1100], Loss: 0.03672858322488537\n",
      "Epoch [828/1100], Loss: 0.03620777160858779\n",
      "Epoch [829/1100], Loss: 0.03569321438862971\n",
      "Epoch [830/1100], Loss: 0.035185563480808923\n",
      "Epoch [831/1100], Loss: 0.03468404001091585\n",
      "Epoch [832/1100], Loss: 0.034187845172027664\n",
      "Epoch [833/1100], Loss: 0.03369915679854785\n",
      "Epoch [834/1100], Loss: 0.033215607329339036\n",
      "Epoch [835/1100], Loss: 0.032738112799279406\n",
      "Epoch [836/1100], Loss: 0.03226702686771432\n",
      "Epoch [837/1100], Loss: 0.031801122636352375\n",
      "Epoch [838/1100], Loss: 0.03134171159513244\n",
      "Epoch [839/1100], Loss: 0.030887095669640985\n",
      "Epoch [840/1100], Loss: 0.030439269076850906\n",
      "Epoch [841/1100], Loss: 0.029996953028103235\n",
      "Epoch [842/1100], Loss: 0.02956068185199001\n",
      "Epoch [843/1100], Loss: 0.02912836497966964\n",
      "Epoch [844/1100], Loss: 0.028703862227530408\n",
      "Epoch [845/1100], Loss: 0.028281975840400264\n",
      "Epoch [846/1100], Loss: 0.02787012401404354\n",
      "Epoch [847/1100], Loss: 0.027459766120500717\n",
      "Epoch [848/1100], Loss: 0.02706372252669098\n",
      "Epoch [849/1100], Loss: 0.026667586300391122\n",
      "Epoch [850/1100], Loss: 0.02630041316660936\n",
      "Epoch [851/1100], Loss: 0.02593980999085943\n",
      "Epoch [852/1100], Loss: 0.02565423528176325\n",
      "Epoch [853/1100], Loss: 0.02543173611138627\n",
      "Epoch [854/1100], Loss: 0.025459760153353272\n",
      "Epoch [855/1100], Loss: 0.02580691394268797\n",
      "Epoch [856/1100], Loss: 0.0269650458049\n",
      "Epoch [857/1100], Loss: 0.02875382232832635\n",
      "Epoch [858/1100], Loss: 0.03100029747292865\n",
      "Epoch [859/1100], Loss: 0.030424201693676878\n",
      "Epoch [860/1100], Loss: 0.027503507168148644\n",
      "Epoch [861/1100], Loss: 0.0241735290910583\n",
      "Epoch [862/1100], Loss: 0.025142779417592465\n",
      "Epoch [863/1100], Loss: 0.028876133117591962\n",
      "Epoch [864/1100], Loss: 0.03464404374244623\n",
      "Epoch [865/1100], Loss: 0.036321623530511715\n",
      "Epoch [866/1100], Loss: 0.02952554982039146\n",
      "Epoch [867/1100], Loss: 0.022413823564420454\n",
      "Epoch [868/1100], Loss: 0.020462467367906356\n",
      "Epoch [869/1100], Loss: 0.021594572696812975\n",
      "Epoch [870/1100], Loss: 0.02107352960956632\n",
      "Epoch [871/1100], Loss: 0.019921298177223434\n",
      "Epoch [872/1100], Loss: 0.01906558190330543\n",
      "Epoch [873/1100], Loss: 0.01873421250638785\n",
      "Epoch [874/1100], Loss: 0.01856414937719819\n",
      "Epoch [875/1100], Loss: 0.01814611143890943\n",
      "Epoch [876/1100], Loss: 0.017798796817260154\n",
      "Epoch [877/1100], Loss: 0.017490309693130257\n",
      "Epoch [878/1100], Loss: 0.01717671317078384\n",
      "Epoch [879/1100], Loss: 0.016927911907487214\n",
      "Epoch [880/1100], Loss: 0.01665245019194117\n",
      "Epoch [881/1100], Loss: 0.016384265860324376\n",
      "Epoch [882/1100], Loss: 0.016124641914075255\n",
      "Epoch [883/1100], Loss: 0.015859836054517018\n",
      "Epoch [884/1100], Loss: 0.015616158141938286\n",
      "Epoch [885/1100], Loss: 0.015370202426083779\n",
      "Epoch [886/1100], Loss: 0.015124891844834565\n",
      "Epoch [887/1100], Loss: 0.014886660173999644\n",
      "Epoch [888/1100], Loss: 0.0146480300805365\n",
      "Epoch [889/1100], Loss: 0.014416221482861147\n",
      "Epoch [890/1100], Loss: 0.014187557311345245\n",
      "Epoch [891/1100], Loss: 0.013960438060394154\n",
      "Epoch [892/1100], Loss: 0.013738317951947465\n",
      "Epoch [893/1100], Loss: 0.013517565338815984\n",
      "Epoch [894/1100], Loss: 0.013300736616940867\n",
      "Epoch [895/1100], Loss: 0.013087456763514638\n",
      "Epoch [896/1100], Loss: 0.012876116996267228\n",
      "Epoch [897/1100], Loss: 0.01266906349655983\n",
      "Epoch [898/1100], Loss: 0.012464093079188387\n",
      "Epoch [899/1100], Loss: 0.01226225316622731\n",
      "Epoch [900/1100], Loss: 0.012063441956570387\n",
      "Epoch [901/1100], Loss: 0.01186694013495071\n",
      "Epoch [902/1100], Loss: 0.011673568290461844\n",
      "Epoch [903/1100], Loss: 0.01148282130111511\n",
      "Epoch [904/1100], Loss: 0.011295215703739814\n",
      "Epoch [905/1100], Loss: 0.011109880000560679\n",
      "Epoch [906/1100], Loss: 0.010927525662054904\n",
      "Epoch [907/1100], Loss: 0.01074813059454982\n",
      "Epoch [908/1100], Loss: 0.010570754514503733\n",
      "Epoch [909/1100], Loss: 0.010395795717386136\n",
      "Epoch [910/1100], Loss: 0.010223765577620725\n",
      "Epoch [911/1100], Loss: 0.01005396091863986\n",
      "Epoch [912/1100], Loss: 0.009887094156738385\n",
      "Epoch [913/1100], Loss: 0.00972273131219481\n",
      "Epoch [914/1100], Loss: 0.009560168739881192\n",
      "Epoch [915/1100], Loss: 0.009400383091644926\n",
      "Epoch [916/1100], Loss: 0.009243133588825003\n",
      "Epoch [917/1100], Loss: 0.009087825561266527\n",
      "Epoch [918/1100], Loss: 0.008934710093001286\n",
      "Epoch [919/1100], Loss: 0.00878411842791138\n",
      "Epoch [920/1100], Loss: 0.008636135090000607\n",
      "Epoch [921/1100], Loss: 0.00848978313894122\n",
      "Epoch [922/1100], Loss: 0.008345767965693085\n",
      "Epoch [923/1100], Loss: 0.008203933856805179\n",
      "Epoch [924/1100], Loss: 0.008064452129531219\n",
      "Epoch [925/1100], Loss: 0.007926750765363977\n",
      "Epoch [926/1100], Loss: 0.007790971340909891\n",
      "Epoch [927/1100], Loss: 0.007657648364329361\n",
      "Epoch [928/1100], Loss: 0.007526211878939648\n",
      "Epoch [929/1100], Loss: 0.007396796069087941\n",
      "Epoch [930/1100], Loss: 0.007269263633588707\n",
      "Epoch [931/1100], Loss: 0.007143709501178819\n",
      "Epoch [932/1100], Loss: 0.007020289524461987\n",
      "Epoch [933/1100], Loss: 0.0068984974561772106\n",
      "Epoch [934/1100], Loss: 0.006778823861623096\n",
      "Epoch [935/1100], Loss: 0.006660659624003529\n",
      "Epoch [936/1100], Loss: 0.006544377827651715\n",
      "Epoch [937/1100], Loss: 0.006429743520868669\n",
      "Epoch [938/1100], Loss: 0.006317395389089597\n",
      "Epoch [939/1100], Loss: 0.006206198190739087\n",
      "Epoch [940/1100], Loss: 0.006097424808615415\n",
      "Epoch [941/1100], Loss: 0.005989835410730393\n",
      "Epoch [942/1100], Loss: 0.005884321196617748\n",
      "Epoch [943/1100], Loss: 0.005779615927622217\n",
      "Epoch [944/1100], Loss: 0.005677976900187787\n",
      "Epoch [945/1100], Loss: 0.005576251670220245\n",
      "Epoch [946/1100], Loss: 0.005478345897302006\n",
      "Epoch [947/1100], Loss: 0.0053793380221236475\n",
      "Epoch [948/1100], Loss: 0.005284722561839317\n",
      "Epoch [949/1100], Loss: 0.005188983691823523\n",
      "Epoch [950/1100], Loss: 0.0050991124758184014\n",
      "Epoch [951/1100], Loss: 0.005005763571034549\n",
      "Epoch [952/1100], Loss: 0.00492276637305622\n",
      "Epoch [953/1100], Loss: 0.0048339617478632135\n",
      "Epoch [954/1100], Loss: 0.004764688769682834\n",
      "Epoch [955/1100], Loss: 0.004688641625989476\n",
      "Epoch [956/1100], Loss: 0.004657868508957108\n",
      "Epoch [957/1100], Loss: 0.004633576842934417\n",
      "Epoch [958/1100], Loss: 0.00473478278672701\n",
      "Epoch [959/1100], Loss: 0.004927474117721431\n",
      "Epoch [960/1100], Loss: 0.005521733728528488\n",
      "Epoch [961/1100], Loss: 0.0065404816741647664\n",
      "Epoch [962/1100], Loss: 0.008693961965036578\n",
      "Epoch [963/1100], Loss: 0.011553032833035104\n",
      "Epoch [964/1100], Loss: 0.015443734213477\n",
      "Epoch [965/1100], Loss: 0.017977866518776864\n",
      "Epoch [966/1100], Loss: 0.020166464790236205\n",
      "Epoch [967/1100], Loss: 0.021417625714093447\n",
      "Epoch [968/1100], Loss: 0.015802737387275556\n",
      "Epoch [969/1100], Loss: 0.008496135636960389\n",
      "Epoch [970/1100], Loss: 0.003984045983088436\n",
      "Epoch [971/1100], Loss: 0.004715765593573451\n",
      "Epoch [972/1100], Loss: 0.005668532608979149\n",
      "Epoch [973/1100], Loss: 0.004854339440498734\n",
      "Epoch [974/1100], Loss: 0.003584959854833869\n",
      "Epoch [975/1100], Loss: 0.0032371654069720535\n",
      "Epoch [976/1100], Loss: 0.0034363453023615875\n",
      "Epoch [977/1100], Loss: 0.003412382247915957\n",
      "Epoch [978/1100], Loss: 0.003222911532247963\n",
      "Epoch [979/1100], Loss: 0.0030141044783249527\n",
      "Epoch [980/1100], Loss: 0.0029373823720106884\n",
      "Epoch [981/1100], Loss: 0.0029239583427624893\n",
      "Epoch [982/1100], Loss: 0.002862557013031619\n",
      "Epoch [983/1100], Loss: 0.0027945715366968216\n",
      "Epoch [984/1100], Loss: 0.0027213093239879527\n",
      "Epoch [985/1100], Loss: 0.0026652981034658296\n",
      "Epoch [986/1100], Loss: 0.0026214337672172405\n",
      "Epoch [987/1100], Loss: 0.0025683676401513367\n",
      "Epoch [988/1100], Loss: 0.0025195458570124174\n",
      "Epoch [989/1100], Loss: 0.002467400556724897\n",
      "Epoch [990/1100], Loss: 0.0024185846416457935\n",
      "Epoch [991/1100], Loss: 0.002372715864339625\n",
      "Epoch [992/1100], Loss: 0.0023259534084445477\n",
      "Epoch [993/1100], Loss: 0.002281417582935319\n",
      "Epoch [994/1100], Loss: 0.002236277914562379\n",
      "Epoch [995/1100], Loss: 0.002192403411072519\n",
      "Epoch [996/1100], Loss: 0.002149477373507125\n",
      "Epoch [997/1100], Loss: 0.0021070793156923173\n",
      "Epoch [998/1100], Loss: 0.0020658961255435315\n",
      "Epoch [999/1100], Loss: 0.002024890172151572\n",
      "Epoch [1000/1100], Loss: 0.0019849142086059146\n",
      "Epoch [1001/1100], Loss: 0.0019456795758401313\n",
      "Epoch [1002/1100], Loss: 0.0019070709431616706\n",
      "Epoch [1003/1100], Loss: 0.0018692466821903508\n",
      "Epoch [1004/1100], Loss: 0.0018319770806556335\n",
      "Epoch [1005/1100], Loss: 0.0017954576592273952\n",
      "Epoch [1006/1100], Loss: 0.00175937601949272\n",
      "Epoch [1007/1100], Loss: 0.0017240792444681574\n",
      "Epoch [1008/1100], Loss: 0.0016895071321414434\n",
      "Epoch [1009/1100], Loss: 0.001655535478676029\n",
      "Epoch [1010/1100], Loss: 0.0016221411315768819\n",
      "Epoch [1011/1100], Loss: 0.001589432421951642\n",
      "Epoch [1012/1100], Loss: 0.0015572060819977196\n",
      "Epoch [1013/1100], Loss: 0.0015255723836276047\n",
      "Epoch [1014/1100], Loss: 0.0014947679185297602\n",
      "Epoch [1015/1100], Loss: 0.0014642048245150363\n",
      "Epoch [1016/1100], Loss: 0.0014343152698188533\n",
      "Epoch [1017/1100], Loss: 0.001404966079917358\n",
      "Epoch [1018/1100], Loss: 0.0013762425651862031\n",
      "Epoch [1019/1100], Loss: 0.0013479248453336368\n",
      "Epoch [1020/1100], Loss: 0.001320210239100561\n",
      "Epoch [1021/1100], Loss: 0.0012930133139548161\n",
      "Epoch [1022/1100], Loss: 0.0012664343594224192\n",
      "Epoch [1023/1100], Loss: 0.0012400556997818057\n",
      "Epoch [1024/1100], Loss: 0.0012145619812145014\n",
      "Epoch [1025/1100], Loss: 0.0011891377403117076\n",
      "Epoch [1026/1100], Loss: 0.0011644222236100177\n",
      "Epoch [1027/1100], Loss: 0.0011401817976093298\n",
      "Epoch [1028/1100], Loss: 0.0011162411533405248\n",
      "Epoch [1029/1100], Loss: 0.0010928807282652997\n",
      "Epoch [1030/1100], Loss: 0.001069951413455783\n",
      "Epoch [1031/1100], Loss: 0.001047444415235077\n",
      "Epoch [1032/1100], Loss: 0.0010253779979052524\n",
      "Epoch [1033/1100], Loss: 0.0010035768082161667\n",
      "Epoch [1034/1100], Loss: 0.0009824676774314867\n",
      "Epoch [1035/1100], Loss: 0.0009615990204565605\n",
      "Epoch [1036/1100], Loss: 0.0009411716112026625\n",
      "Epoch [1037/1100], Loss: 0.0009212192419454368\n",
      "Epoch [1038/1100], Loss: 0.0009015549751438812\n",
      "Epoch [1039/1100], Loss: 0.0008822728295854176\n",
      "Epoch [1040/1100], Loss: 0.000863359827462773\n",
      "Epoch [1041/1100], Loss: 0.0008448258224689198\n",
      "Epoch [1042/1100], Loss: 0.0008266508314136445\n",
      "Epoch [1043/1100], Loss: 0.000808843764843914\n",
      "Epoch [1044/1100], Loss: 0.0007913780523267633\n",
      "Epoch [1045/1100], Loss: 0.0007742841837625747\n",
      "Epoch [1046/1100], Loss: 0.0007575092115530424\n",
      "Epoch [1047/1100], Loss: 0.0007409889205973741\n",
      "Epoch [1048/1100], Loss: 0.0007249039636008092\n",
      "Epoch [1049/1100], Loss: 0.0007090303899985884\n",
      "Epoch [1050/1100], Loss: 0.0006935207191531845\n",
      "Epoch [1051/1100], Loss: 0.000678269602360615\n",
      "Epoch [1052/1100], Loss: 0.0006634328565269243\n",
      "Epoch [1053/1100], Loss: 0.0006488656750320843\n",
      "Epoch [1054/1100], Loss: 0.0006346014245082188\n",
      "Epoch [1055/1100], Loss: 0.0006204001716128005\n",
      "Epoch [1056/1100], Loss: 0.0006069120445317822\n",
      "Epoch [1057/1100], Loss: 0.000593227104673133\n",
      "Epoch [1058/1100], Loss: 0.000580296083455778\n",
      "Epoch [1059/1100], Loss: 0.0005671668568538735\n",
      "Epoch [1060/1100], Loss: 0.000555045693545253\n",
      "Epoch [1061/1100], Loss: 0.0005423764724241664\n",
      "Epoch [1062/1100], Loss: 0.0005315753771810705\n",
      "Epoch [1063/1100], Loss: 0.0005197253826736414\n",
      "Epoch [1064/1100], Loss: 0.0005113306556268071\n",
      "Epoch [1065/1100], Loss: 0.0005019407919917285\n",
      "Epoch [1066/1100], Loss: 0.0005005465593512781\n",
      "Epoch [1067/1100], Loss: 0.0005012765659557772\n",
      "Epoch [1068/1100], Loss: 0.000525266928889323\n",
      "Epoch [1069/1100], Loss: 0.0005702267735614441\n",
      "Epoch [1070/1100], Loss: 0.0006967503877604031\n",
      "Epoch [1071/1100], Loss: 0.0009389255437781685\n",
      "Epoch [1072/1100], Loss: 0.0014989691408118233\n",
      "Epoch [1073/1100], Loss: 0.0025710280024213716\n",
      "Epoch [1074/1100], Loss: 0.004759052382723894\n",
      "Epoch [1075/1100], Loss: 0.00827708185533993\n",
      "Epoch [1076/1100], Loss: 0.0133866670075804\n",
      "Epoch [1077/1100], Loss: 0.018264865007949993\n",
      "Epoch [1078/1100], Loss: 0.021672164526535198\n",
      "Epoch [1079/1100], Loss: 0.024896554823499173\n",
      "Epoch [1080/1100], Loss: 0.01606523918962921\n",
      "Epoch [1081/1100], Loss: 0.0067346644718782045\n",
      "Epoch [1082/1100], Loss: 0.0009677962952991948\n",
      "Epoch [1083/1100], Loss: 0.0022643294068984687\n",
      "Epoch [1084/1100], Loss: 0.003583840938517824\n",
      "Epoch [1085/1100], Loss: 0.002049534614343429\n",
      "Epoch [1086/1100], Loss: 0.0005341641262930352\n",
      "Epoch [1087/1100], Loss: 0.00040445391277899034\n",
      "Epoch [1088/1100], Loss: 0.0007733508739420358\n",
      "Epoch [1089/1100], Loss: 0.0007093595086189453\n",
      "Epoch [1090/1100], Loss: 0.00042098655922018224\n",
      "Epoch [1091/1100], Loss: 0.0002807287885389087\n",
      "Epoch [1092/1100], Loss: 0.00031280244638765\n",
      "Epoch [1093/1100], Loss: 0.00034400080221530516\n",
      "Epoch [1094/1100], Loss: 0.00030605558845309133\n",
      "Epoch [1095/1100], Loss: 0.00026229670129396254\n",
      "Epoch [1096/1100], Loss: 0.0002481675410308526\n",
      "Epoch [1097/1100], Loss: 0.0002482566262642649\n",
      "Epoch [1098/1100], Loss: 0.0002469790883878886\n",
      "Epoch [1099/1100], Loss: 0.0002347461424960784\n",
      "Epoch [1100/1100], Loss: 0.00022513765770781902\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "\n",
    "num_epochs = 1100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    total_loss = 0  \n",
    "\n",
    "    for sequence, label in zip(sequences, labels):  \n",
    "        # Convert sequence to tensor (add batch dimension)\n",
    "        input_sequence = torch.tensor(sequence, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)\n",
    "        target = torch.tensor([label], dtype=torch.float32)  # Convert label to tensor\n",
    "\n",
    "        output= model(input_sequence)\n",
    "\n",
    "        # Compute loss (mean squared error)\n",
    "        loss = loss_fn(output, target)  # Squeeze batch dimension after output\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Print the average loss after each epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(sequences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sum for the sequence [10, 11, 12]: 32.97019577026367\n"
     ]
    }
   ],
   "source": [
    "# Test the model with some sample sequences\n",
    "model.eval()\n",
    "\n",
    "# Test the model on a new sequence\n",
    "test_sequence = [10,11,12] \n",
    "test_input = torch.tensor(test_sequence, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "with torch.inference_mode():  \n",
    "    predicted_output = model(test_input)\n",
    "\n",
    "predicted_sum = predicted_output.item()  # Convert to scalar\n",
    "\n",
    "print(f\"Predicted sum for the sequence {test_sequence}: {predicted_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
